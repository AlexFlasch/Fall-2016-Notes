#Stats 11/3/16

#Sampling Theory

##Random Sampling

Suppose that you want to learn about the average height of *all* the students on campus.

You know that a **sample** must suffice, as gathering data on the entire **population** is infeasible.  
The key to a proper sampling procedure is that every student in the population must have an *equal* chance of appearing in the sample.  
A sampling process that has this feature is called *random sampling*, and it results in a *random sample*.

Suppose to gather a sample of height data from students, you decide to start by surveying sororities on campus.  
This would not give you a random sample.  
What if you salso surveyed fraternities as well? Would the sample be representative of the population now?  
No.

We have to be careful when conducting sampling, because if our sampling procedure is biased towards over or under-representing one demographic characteristic (women) or another, our sample will not accurately represent the population.  
You can avoid biased estimates by using a proper random sampling process wherein every student in the population has an equal chance of appearing in the sample.

Maybe, recognizing these problems, you instead randomly choose students from the directory and send out surveys asking them to report their own height.  
While this would likely ensure that each student has an equal chance of appearing in your sample, it runs into two other problems:

* Reporting errors
* Non-response bias

There are a variety of ways to construct a random sampling process, most of which revolve around the *simple random sample*.  
The modern approach is to use RNG.


##Sampling Error

Assuming your sample size is adequately large and was collected properly, you can resonably expect your sample information to be useful.  
However, a question still remains: Just how good is "good" sample information?  
We cannot expect a sample to perfectly reflect the entire population -- there will be differences between sample estimates (like a sample mean) and population parameters (like a population mean).  
This difference is called *sampling error*, and we need to gauge it somehow because we need to *know* that our sample is providing an accurate estimate of the population.

Regarding the student height sample, suppose we sample 100 students properly.  
Would you expect the sample average height to *exactly* equal the average height of all students on campus?  
That's very unlikely, the sample average will miss the mark by some amount -- this amount *is* the sampling error.  

In practice, we will rarely be privileged with exact knowledge of population parameter values, and so we must instead estimate them using data.  
To estimate a population's parameters using samplme data is to learn about that population.  
For this we use the *analogy principle*, which matches sample information to its population counterpart.

Sample statistics and the corresponding population parameters

|Sample Statistic|Population Parameter|Designation|
|----------------|----------|---|
| $\bar{X}$ |$\mu$|mean|
|$\hat{\pi}$|$\pi$|proportion|
|    $s$    |$\sigma$|standard deviation|
|   $s^2$   |$\sigma$|variance|
|  $s_{xy}$ |$\sigma_{xy}$|covariance|
|    $r$    |$\rho$|correlation|

As we cannot expect a given $\bar{X}$ to exactly equal $\mu$, we must ask "How large is the sample error?" Is the estimate close enough to the parameter?  

###Sampling Distributions

A sampling distribution is always a distribution of a sample statistic and **_not_** a distribution of the data in a population.  
To understand sampling distributions you must understand that sample statistics, like $\bar{X}$ and $\hat{\pi}$, are random variables.  
For example, suppose we want to study the GPA of students in this class, and assume that there are 40 students enrolled.  
Suppose further that we only have time to randomly sample five students. So, our population is the class and the sample includes five students from the class.  

But if we randomly selected 5 students again, we wouldn't get the same sample average.  
This can be represented as:  
${40 \choose 5} = \frac{40!}{35! \cdot 5!} = 658008$  
658008 different possible samples of size five.  
Therefore, each possible sample mean has only a $\frac{1}{658008}$ chance of occuring, and providing us with a **distribution** of possible sample estimates we **could** have obtained.  
So, how are these different $\bar{X}$'s related?


##Central Limit Theorem

Informally:

If we use a *large* ($n \geq 30$) simple random sample, it doesn't matter what type of population your data comes from. The *central limit theorem* enables us to conclude that the sampling distribution of $\bar{X}$ can be approximated by a normal proabability distribution.  
The distribution of $X$, where the data are generated, need not be normal or even known.  
Remember: Within the central limit theorem, the sample mean $\bar{X}$ is a random variable.

###Example 1

Consider a population characterized by the uniform random variable $X \approx U[25, 35]$  
According to the central limit theorem, the sampling distribution of the sample average from any population should look bell-shaped for a suitably large smaple size.  
To explore this, imagine that we have 1000 samples of size 2, 1000 samples of size 10, and 1000 samples of size 30, all of which are proper random samples from $U[25, 35]$.

Formally:  
If $n$ values are independently drawn from the same population, then  
$\bar{X} \approx N(\mu, \sigma / \sqrt{n})$  
that is, the random variable $\bar{X}$ approximately follows a normal distribution with $E(\bar{X}) = \mu$ and $V(\bar{X}) = \sigma^2 / n$  
This is called the sampling distribution of the sample mean, and it applies when $n$ is suitably large (typically 30 or more).  
Applying the $z$ transformation implies that  
$\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \approx N(0, 1)$  
where $]sigma / \sqrt{n}$ is the *standard error*

Suppose that you select a random sample of size 144 from a normal population with a mean of 200 and a standard deviation of 6. What is the $Pr(\bar{X} > 201)$  
Formula for standard error is $\sigma / \sqrt{n}$, so here it equals $6 / \sqrt{144} = 0.5$  
To find $Pr(\bar{X} > 201)$ we need to apply the central limit theorem and employ the four-step method from Chapter 6  

Draw the sampling distribution of $\bar{X}$ ( a normal distribution), label the mean, label the axis, and then shade the desired probability.  
Apply the $z$ transformation to the event $\bar{X} > 201$:  

$Pr(\bar{X} > 201) = Pr(\frac{\bar{X} - \mu}{\sigma / \sqrt{n}} > \frac{201 - \mu}{\sigma / \sqrt{n}})$  
$ = Pr(Z > \frac{ 201 - 200}{6 / \sqrt{144}})$  
$ = Pr(Z > \frac{201 - 200}{0.5})$  
$ = Pr(Z > 2)$

Refer to the $Z$ table and solve. THe specific value $z = 2$ implies the shaded area equals 0.0228.  
So the $Pr(Z > 2) = 0.0228$, which implies that the $Pr(\bar{X} > 201) = 0.0228$.